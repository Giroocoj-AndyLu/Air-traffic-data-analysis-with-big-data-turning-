{"cells":[{"cell_type":"markdown","source":["# Task 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c2a9f35-069d-4f0c-87a6-2ac344ff8a07"}}},{"cell_type":"code","source":["dbfs_fileStore_prefix = \"/FileStore/tables\"\nprefix = \"ontimeperformance\"\nsize = \"small\"\nyear = 2000"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bcb21718-4855-46a6-8ff9-20d9c7b2230e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.streaming import StreamingContext\nimport pyspark.sql.functions as f\nfrom pyspark.sql.functions import col, avg, min, max, abs, concat_ws, rank\nfrom pyspark.sql.window import Window\nimport pandas as pd\nimport numpy as np\nfrom pyspark.statcounter import StatCounter\nfrom sparkmeasure import StageMetrics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c033b51e-1095-4212-ada2-02370ba2a28a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def task_2(spark_session, flights_path, airlines_path, year):\n  stagemetrics = StageMetrics(spark)\n  stagemetrics.begin()\n  ss=spark_session.builder\n    \n  #clean the Schema of flights\n  clean_space_Schema = StructType([StructField('carrier_code', StringType(), True),\n                     StructField('flight_number', StringType(), True),\n                     StructField('flight_date', StringType(), True),\n                     StructField('origin', StringType(), True),\n                     StructField('destination', StringType(), True),\n                     StructField('tailnum', StringType(), True),\n                     StructField('scheduled_departure_time', StringType(), True),\n                     StructField('scheduled_arrival_time', StringType(), True),\n                     StructField('actual_departure_time', StringType(), True),\n                     StructField('actual_arrival_time', StringType(), True),\n                     StructField('distance', StringType(), True)])\n  DF_Flights = spark.read.format(\"csv\").option(\"header\", \"true\").schema(clean_space_Schema).load(flights_path)[['carrier_code', 'flight_date', 'scheduled_departure_time', 'actual_departure_time']].cache()\n  DF_Airlines = spark.read.csv(airlines_path, header=\"true\")[['carrier_code', 'name', 'country']].cache()\n  \n  #clean the null value\n  DF_Flights_clean=DF_Flights.na.drop()\n  DF_Airlines_clean=DF_Airlines.na.drop()\n  \n  #filter US airlines\n  us_c_n = DF_Airlines_clean.select('carrier_code', 'name').filter(\"country='United States'\").dropDuplicates()\n  \n  #filter year \n  DF_Flights_clean = DF_Flights_clean.filter(f.col(\"flight_date\").substr(0,4) == str(year)).cache()\n  \n  #conver to minutes\n  DF_Flights_clean = DF_Flights_clean.withColumn('scheduled_departure_time', f.col('scheduled_departure_time').substr(0,2).cast(\"int\")*60 + f.col('scheduled_departure_time').substr(4,2).cast(\"int\"))\n  DF_Flights_clean = DF_Flights_clean.withColumn('actual_departure_time', f.col('actual_departure_time').substr(0,2).cast(\"int\")*60 + f.col('actual_departure_time').substr(4,2).cast(\"int\"))\n                                  \n  #filter next_day's delay \n  DF_Flights_clean = DF_Flights_clean.withColumn(\"actual_departure_time\", f.when(f.col(\"actual_departure_time\").cast(\"int\") -f.col(\"scheduled_departure_time\").cast(\"int\") < -720, f.col(\"actual_departure_time\").cast(\"int\") + 1440).otherwise(f.col(\"actual_departure_time\").cast(\"int\")))\n  \n  #filter delay's flight\n  DF_Flights_delay = DF_Flights_clean.filter(f.col(\"scheduled_departure_time\").cast(\"int\") < f.col(\"actual_departure_time\").cast(\"int\")).cache()\n  \n  #calculate how long the delay is \n  DF_Flights_delay = DF_Flights_delay.withColumn(\"delay\", f.col(\"actual_departure_time\").cast(\"int\") - f.col(\"scheduled_departure_time\").cast(\"int\"))\n  \n  #join US airline\n  join_DF_us_airline = us_c_n.join(DF_Flights_delay, on=['carrier_code'], how='inner').cache()\n  \n  \n  #calculate mean + count + min + max\n  ave_max_min = join_DF_us_airline.withColumn('delay', f.col('delay')).groupBy('name').agg(\n    f.count(f.col(\"name\")).alias(\"num_delays\"),\n    f.avg(f.col(\"delay\").cast(\"int\")).alias(\"average_delay\"),\n    f.min(f.col(\"delay\").cast(\"int\")).alias(\"min_delay\"),\n    f.max(f.col(\"delay\").cast(\"int\")).alias(\"max_delay\")\n  )\n  #timestampe\n  #.cast().cast(long)\n  \n  # rename\n  ave_max_min = ave_max_min.withColumnRenamed(\"name\", \"airline_name\")\n  \n  display(ave_max_min)\n  stagemetrics.end()\n  stagemetrics.print_report()\n  #ave_max_min.write.format(\"com.databricks.spark.csv\").option(\"delimiter\",\"\\t\").csv(\"/FileStore/task2dataframe_result/resulttask2_file.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11dd8a14-e921-4424-92ca-a7d0135785f7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["task_2(spark, f\"{dbfs_fileStore_prefix}/{prefix}_flights_{size}.csv\", f\"{dbfs_fileStore_prefix}/{prefix}_airlines.csv\", year)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dad94962-7ab5-487f-8c1f-bd1169e93064"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["United Airlines",385,35.212987012987014,1,906],["Southwest Airlines Co.",279,38.71326164874552,1,189],["Continental Air Lines Inc.",184,18.57608695652174,1,236],["Northwest Airlines Inc.",242,21.446280991735538,1,237],["US Airways",361,20.63711911357341,1,476],["Alaska Airlines Inc.",58,37.87931034482759,1,120],["Delta Air Lines Inc.",487,24.876796714579054,1,1375],["American Airlines Inc.",310,32.07096774193548,1,1146]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"airline_name","type":"\"string\"","metadata":"{}"},{"name":"num_delays","type":"\"long\"","metadata":"{}"},{"name":"average_delay","type":"\"double\"","metadata":"{}"},{"name":"min_delay","type":"\"integer\"","metadata":"{}"},{"name":"max_delay","type":"\"integer\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>airline_name</th><th>num_delays</th><th>average_delay</th><th>min_delay</th><th>max_delay</th></tr></thead><tbody><tr><td>United Airlines</td><td>385</td><td>35.212987012987014</td><td>1</td><td>906</td></tr><tr><td>Southwest Airlines Co.</td><td>279</td><td>38.71326164874552</td><td>1</td><td>189</td></tr><tr><td>Continental Air Lines Inc.</td><td>184</td><td>18.57608695652174</td><td>1</td><td>236</td></tr><tr><td>Northwest Airlines Inc.</td><td>242</td><td>21.446280991735538</td><td>1</td><td>237</td></tr><tr><td>US Airways</td><td>361</td><td>20.63711911357341</td><td>1</td><td>476</td></tr><tr><td>Alaska Airlines Inc.</td><td>58</td><td>37.87931034482759</td><td>1</td><td>120</td></tr><tr><td>Delta Air Lines Inc.</td><td>487</td><td>24.876796714579054</td><td>1</td><td>1375</td></tr><tr><td>American Airlines Inc.</td><td>310</td><td>32.07096774193548</td><td>1</td><td>1146</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 1\nnumTasks =&gt; 1\nelapsedTime =&gt; 235 (0.2 s)\nstageDuration =&gt; 235 (0.2 s)\nexecutorRunTime =&gt; 210 (0.2 s)\nexecutorCpuTime =&gt; 51 (51 ms)\nexecutorDeserializeTime =&gt; 4 (4 ms)\nexecutorDeserializeCpuTime =&gt; 3 (3 ms)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 36 (36 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 0 (0 ms)\nresultSize =&gt; 1372 (1372 Bytes)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 1\nbytesRead =&gt; 0 (0 Bytes)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 0\nshuffleTotalBlocksFetched =&gt; 0\nshuffleLocalBlocksFetched =&gt; 0\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 0 (0 Bytes)\nshuffleLocalBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsWritten =&gt; 0\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 1\nnumTasks =&gt; 1\nelapsedTime =&gt; 235 (0.2 s)\nstageDuration =&gt; 235 (0.2 s)\nexecutorRunTime =&gt; 210 (0.2 s)\nexecutorCpuTime =&gt; 51 (51 ms)\nexecutorDeserializeTime =&gt; 4 (4 ms)\nexecutorDeserializeCpuTime =&gt; 3 (3 ms)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 36 (36 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 0 (0 ms)\nresultSize =&gt; 1372 (1372 Bytes)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 1\nbytesRead =&gt; 0 (0 Bytes)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 0\nshuffleTotalBlocksFetched =&gt; 0\nshuffleLocalBlocksFetched =&gt; 0\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 0 (0 Bytes)\nshuffleLocalBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsWritten =&gt; 0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def task_2_RDD(spark_session, flights_path, airlines_path, year):\n  ss=spark_session.builder\n  stagemetrics = StageMetrics(spark)\n  stagemetrics.begin()\n  #clean the Schema of flights\n  clean_space_Schema = StructType([StructField('carrier_code', StringType(), True),\n                     StructField('flight_number', StringType(), True),\n                     StructField('flight_date', StringType(), True),\n                     StructField('origin', StringType(), True),\n                     StructField('destination', StringType(), True),\n                     StructField('tailnum', StringType(), True),\n                     StructField('scheduled_departure_time', StringType(), True),\n                     StructField('scheduled_arrival_time', StringType(), True),\n                     StructField('actual_departure_time', StringType(), True),\n                     StructField('actual_arrival_time', StringType(), True),\n                     StructField('distance', StringType(), True)])\n  \n  #import data\n  DF_Flights = spark.read.format(\"csv\").option(\"header\", \"true\").schema(clean_space_Schema).load(flights_path)[['carrier_code', 'flight_date', 'scheduled_departure_time', 'actual_departure_time']].dropna()\n  DF_Airlines = spark.read.csv(airlines_path, header=\"true\")[['carrier_code', 'name', 'country']].dropna()\n  \n  #create rdd\n  rdd_Flight = DF_Flights.rdd\n  rdd_Airlines = DF_Airlines.rdd\n  \n  #filter the US Airlines\n  us_airlines = rdd_Airlines.filter(lambda x: x[2] == 'United States')\n  \n  #filter year\n  year_flight = rdd_Flight.filter(lambda x: x[1][0:4] == str(year))\n  \n  #create key\n  key_us_airlines = us_airlines.map(lambda x: (x[0], x[1]))\n  key_year_flight = year_flight.map(lambda x: (x[0], x[2:]))\n  \n  #join\n  newRdd = key_us_airlines.join(key_year_flight)\n  \n  #calculate delay\n  count = newRdd.map(lambda x:(x[1][0], (int(x[1][1][1][0:2])*60 + int(x[1][1][1][2:4])) - (int(x[1][1][0][0:2])*60 + int(x[1][1][0][2:4])) ))\n  # count = count.filter(lambda x: x[1] > 0)\n  \n  #filter delay next day ?? Assume\n  count = count.map(lambda x: (x[0], x[1]+24*60) if x[1] < -12*60 else (x[0], x[1]))\n  \n  #filter delayed flights\n  count = count.filter(lambda x: x[1] > 0)\n  \n  #calculate num_delay\n  num_delay = count.map(lambda x:(x[0], 1) if x[1] > 0 else (x[0], 0))\n  num_delay = num_delay.reduceByKey(lambda x,y: (x+y))\n  \n  #calculate average_delay\n  sum_delay = count.map(lambda x:(x[0], x[1]) if x[1] > 0 else (x[0], 0))\n  sum_delay = sum_delay.reduceByKey(lambda x,y: (x+y))\n  average_delay = sum_delay.join(num_delay).map(lambda x:(x[0], x[1][0]/x[1][1]))\n  \n  #calculate min_delay\n  min_delay = count.aggregateByKey(StatCounter(), StatCounter.merge, StatCounter.mergeStats).mapValues(lambda s: (s.min()))\n  \n  #calculate max_delay\n  max_delay = count.aggregateByKey(StatCounter(), StatCounter.merge, StatCounter.mergeStats).mapValues(lambda s: (s.max()))\n  \n  print(max_delay.collect())\n  stagemetrics.end()\n  stagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7fb8222-8603-4c98-bb6b-02b528d3fbc6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["task_2_RDD(spark, f\"{dbfs_fileStore_prefix}/{prefix}_flights_massive.csv\", f\"{dbfs_fileStore_prefix}/{prefix}_airlines.csv\", year)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85f12e84-135f-43cb-8d84-85e9a70bcd3d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;Southwest Airlines Co.&#39;, 635.0), (&#39;US Airways&#39;, 1437.0), (&#39;Continental Air Lines Inc.&#39;, 722.0), (&#39;Delta Air Lines Inc.&#39;, 1439.0), (&#39;United Airlines&#39;, 1436.0), (&#39;American Airlines Inc.&#39;, 1440.0), (&#39;Alaska Airlines Inc.&#39;, 696.0), (&#39;Northwest Airlines Inc.&#39;, 1430.0)]\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 4\nnumTasks =&gt; 193\nelapsedTime =&gt; 766002 (13 min)\nstageDuration =&gt; 765648 (13 min)\nexecutorRunTime =&gt; 6035688 (1.7 h)\nexecutorCpuTime =&gt; 2679 (3 s)\nexecutorDeserializeTime =&gt; 9292 (9 s)\nexecutorDeserializeCpuTime =&gt; 1678 (2 s)\nresultSerializationTime =&gt; 2 (2 ms)\njvmGCTime =&gt; 747268 (12 min)\nshuffleFetchWaitTime =&gt; 4 (4 ms)\nshuffleWriteTime =&gt; 894 (0.9 s)\nresultSize =&gt; 178274 (174.0 KB)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 14191\nbytesRead =&gt; 2694075728 (2.0 GB)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 104\nshuffleTotalBlocksFetched =&gt; 104\nshuffleLocalBlocksFetched =&gt; 104\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 24049834 (22.0 MB)\nshuffleLocalBytesRead =&gt; 24049834 (22.0 MB)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 24049834 (22.0 MB)\nshuffleRecordsWritten =&gt; 104\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;Southwest Airlines Co.&#39;, 635.0), (&#39;US Airways&#39;, 1437.0), (&#39;Continental Air Lines Inc.&#39;, 722.0), (&#39;Delta Air Lines Inc.&#39;, 1439.0), (&#39;United Airlines&#39;, 1436.0), (&#39;American Airlines Inc.&#39;, 1440.0), (&#39;Alaska Airlines Inc.&#39;, 696.0), (&#39;Northwest Airlines Inc.&#39;, 1430.0)]\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 4\nnumTasks =&gt; 193\nelapsedTime =&gt; 766002 (13 min)\nstageDuration =&gt; 765648 (13 min)\nexecutorRunTime =&gt; 6035688 (1.7 h)\nexecutorCpuTime =&gt; 2679 (3 s)\nexecutorDeserializeTime =&gt; 9292 (9 s)\nexecutorDeserializeCpuTime =&gt; 1678 (2 s)\nresultSerializationTime =&gt; 2 (2 ms)\njvmGCTime =&gt; 747268 (12 min)\nshuffleFetchWaitTime =&gt; 4 (4 ms)\nshuffleWriteTime =&gt; 894 (0.9 s)\nresultSize =&gt; 178274 (174.0 KB)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 14191\nbytesRead =&gt; 2694075728 (2.0 GB)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 104\nshuffleTotalBlocksFetched =&gt; 104\nshuffleLocalBlocksFetched =&gt; 104\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 24049834 (22.0 MB)\nshuffleLocalBytesRead =&gt; 24049834 (22.0 MB)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 24049834 (22.0 MB)\nshuffleRecordsWritten =&gt; 104\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Task 2_e","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2683552198579768}},"nbformat":4,"nbformat_minor":0}
