{"cells":[{"cell_type":"markdown","source":["# Task 1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c2a9f35-069d-4f0c-87a6-2ac344ff8a07"}}},{"cell_type":"code","source":["dbfs_fileStore_prefix = \"/FileStore/tables\"\nprefix = \"ontimeperformance\"\nsize = \"small\"\nyear = 2000"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bcb21718-4855-46a6-8ff9-20d9c7b2230e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.streaming import StreamingContext\nimport pyspark.sql.functions as f\nfrom pyspark.sql.functions import col, avg, min, max, abs, concat_ws, rank\nfrom pyspark.sql.window import Window\nimport pandas as pd\nimport numpy as np\nfrom pyspark.statcounter import StatCounter\nfrom sparkmeasure import StageMetrics\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0322708-7bbc-4545-9d01-c57d9a1bb288"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def task_1(spark_session, flights_path, aircrafts_path):\n  stagemetrics = StageMetrics(spark)\n  stagemetrics.begin()\n  ss=spark_session.builder\n  #clean the Schema of flights\n  clena_space_Schema = StructType([StructField('carrier_code', StringType(), True),\n                     StructField('flight_number', StringType(), True),\n                     StructField('flight_date', StringType(), True),\n                     StructField('origin', StringType(), True),\n                     StructField('destination', StringType(), True),\n                     StructField('tailnum', StringType(), True),\n                     StructField('scheduled_depature_time', StringType(), True),\n                     StructField('scheduled_arrival_time', StringType(), True),\n                     StructField('actual_departure_time', StringType(), True),\n                     StructField('actual_arrival_time', StringType(), True),\n                     StructField('distance', StringType(), True)])\n  \n  DF_Flights = spark.read.format(\"csv\").option(\"header\", \"true\").schema(clena_space_Schema).load(flights_path).cache()\n  DF_Aircrafts = spark.read.csv(aircrafts_path, header=\"true\").cache()\n  #rename\n  DF_Flights_clean=DF_Flights\n  DF_Aircrafts_clean=DF_Aircrafts\n\n  #find the model that is manufactured by CESSNA\n  CESSNA_ma = DF_Aircrafts_clean.filter(col('manufacturer') == \"CESSNA\").cache()\n\n  join_DF = CESSNA_ma.join(DF_Flights_clean, on=['tailnum'], how='inner')\n  #agg\n  join_DF = join_DF.withColumn('manufacturer',f.lower(f.col('manufacturer')))\n  join_DF = join_DF.withColumn('manufacturer',f.initcap(f.col('manufacturer')))\n  \n  #get the pure numeric value of the model\n  join_DF = join_DF.withColumn(\"model\",f.regexp_extract(\"model\", \"\\\\d+\", 0))\n\n  #get first three digit\n  join_DF = join_DF.withColumn('model',f.col('model').substr(0,3))\n  \n  #groupby\n  join_DF = join_DF.withColumn('model',f.col('model')).groupBy('manufacturer','model').count().sort('count',ascending=False).limit(3)\n\n  join_DF = join_DF.select(f.format_string('%s %s', join_DF.manufacturer, join_DF.model).alias('models'),f.col('count').alias('numberOfDepartingFlights'))\n  display(join_DF)\n  \n  stagemetrics.end()\n  stagemetrics.print_report()\n  # formatting and out put the result\n  \n  #join_DF.write.format(\"com.databricks.spark.csv\").option(\"delimiter\",\"\\t\").csv(\"/FileStore/task1dataframe_result/resulttask1_file.csv\")\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f093baa0-f502-4575-a57d-47fceaefe507"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["task_1(spark, f\"{dbfs_fileStore_prefix}/{prefix}_flights_small.csv\", f\"{dbfs_fileStore_prefix}/{prefix}_aircrafts.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ca4b415-20f5-4e09-9acf-3b0b9b2b1e47"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Cessna 172",57],["Cessna 210",48],["Cessna 421",47]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"models","type":"\"string\"","metadata":"{}"},{"name":"numberOfDepartingFlights","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>models</th><th>numberOfDepartingFlights</th></tr></thead><tbody><tr><td>Cessna 172</td><td>57</td></tr><tr><td>Cessna 210</td><td>48</td></tr><tr><td>Cessna 421</td><td>47</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 1\nnumTasks =&gt; 1\nelapsedTime =&gt; 118 (0.1 s)\nstageDuration =&gt; 118 (0.1 s)\nexecutorRunTime =&gt; 93 (93 ms)\nexecutorCpuTime =&gt; 11 (11 ms)\nexecutorDeserializeTime =&gt; 3 (3 ms)\nexecutorDeserializeCpuTime =&gt; 3 (3 ms)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 0 (0 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 0 (0 ms)\nresultSize =&gt; 1377 (1377 Bytes)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 1\nbytesRead =&gt; 0 (0 Bytes)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 0\nshuffleTotalBlocksFetched =&gt; 0\nshuffleLocalBlocksFetched =&gt; 0\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 0 (0 Bytes)\nshuffleLocalBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsWritten =&gt; 0\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 1\nnumTasks =&gt; 1\nelapsedTime =&gt; 118 (0.1 s)\nstageDuration =&gt; 118 (0.1 s)\nexecutorRunTime =&gt; 93 (93 ms)\nexecutorCpuTime =&gt; 11 (11 ms)\nexecutorDeserializeTime =&gt; 3 (3 ms)\nexecutorDeserializeCpuTime =&gt; 3 (3 ms)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 0 (0 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 0 (0 ms)\nresultSize =&gt; 1377 (1377 Bytes)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 1\nbytesRead =&gt; 0 (0 Bytes)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 0\nshuffleTotalBlocksFetched =&gt; 0\nshuffleLocalBlocksFetched =&gt; 0\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 0 (0 Bytes)\nshuffleLocalBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsWritten =&gt; 0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["task_1(spark, f\"{dbfs_fileStore_prefix}/{prefix}_flights_massive.csv\", f\"{dbfs_fileStore_prefix}/{prefix}_aircrafts.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7305042-031d-4c6d-b5c8-ee9390240363"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Cessna 210",37771],["Cessna 172",32853],["Cessna 421",32817]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"models","type":"\"string\"","metadata":"{}"},{"name":"numberOfDepartingFlights","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>models</th><th>numberOfDepartingFlights</th></tr></thead><tbody><tr><td>Cessna 210</td><td>37771</td></tr><tr><td>Cessna 172</td><td>32853</td></tr><tr><td>Cessna 421</td><td>32817</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 1\nnumTasks =&gt; 1\nelapsedTime =&gt; 183 (0.2 s)\nstageDuration =&gt; 183 (0.2 s)\nexecutorRunTime =&gt; 168 (0.2 s)\nexecutorCpuTime =&gt; 43 (43 ms)\nexecutorDeserializeTime =&gt; 3 (3 ms)\nexecutorDeserializeCpuTime =&gt; 3 (3 ms)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 0 (0 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 0 (0 ms)\nresultSize =&gt; 1377 (1377 Bytes)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 1\nbytesRead =&gt; 0 (0 Bytes)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 0\nshuffleTotalBlocksFetched =&gt; 0\nshuffleLocalBlocksFetched =&gt; 0\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 0 (0 Bytes)\nshuffleLocalBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsWritten =&gt; 0\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 1\nnumTasks =&gt; 1\nelapsedTime =&gt; 183 (0.2 s)\nstageDuration =&gt; 183 (0.2 s)\nexecutorRunTime =&gt; 168 (0.2 s)\nexecutorCpuTime =&gt; 43 (43 ms)\nexecutorDeserializeTime =&gt; 3 (3 ms)\nexecutorDeserializeCpuTime =&gt; 3 (3 ms)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 0 (0 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 0 (0 ms)\nresultSize =&gt; 1377 (1377 Bytes)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 1\nbytesRead =&gt; 0 (0 Bytes)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 0\nshuffleTotalBlocksFetched =&gt; 0\nshuffleLocalBlocksFetched =&gt; 0\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 0 (0 Bytes)\nshuffleLocalBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsWritten =&gt; 0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def task_1_RDD1(spark_session, flights_path, aircrafts_path):\n  stagemetrics = StageMetrics(spark)\n  stagemetrics.begin()\n  s_s=spark_session.builder\n  \n  #\n  #clean the Schema of flights\n  clean_space_Schema = StructType([StructField('carrier_code', StringType(), True),\n                     StructField('flight_number', StringType(), True),\n                     StructField('flight_date', StringType(), True),\n                     StructField('origin', StringType(), True),\n                     StructField('destination', StringType(), True),\n                     StructField('tailnum', StringType(), True),\n                     StructField('scheduled_depature_time', StringType(), True),\n                     StructField('scheduled_arrival_time', StringType(), True),\n                     StructField('actual_departure_time', StringType(), True),\n                     StructField('actual_arrival_time', StringType(), True),\n                     StructField('distance', StringType(), True)])\n  \n  Flights_df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(clean_space_Schema).load(flights_path)\n  Aircrafts_df = spark.read.csv(aircrafts_path, header=\"true\")\n  \n  # create rdd of the dataframe\n  Flights_rdd = Flights_df.rdd\n  Aircrafts_rdd = Aircrafts_df.rdd\n  \n  #filter the manufactural\n  manufact_filter = Aircrafts_rdd.filter(lambda x: x[\"manufacturer\"] == 'CESSNA')\n  Flights_filter  = Flights_rdd.filter(lambda x: x[\"tailnum\"] != None)\n  \n  #filter the key that only leave tailnum manu and model\n  key_manufact_filter = manufact_filter.map(lambda x: (x[0], x[2:]))\n  \n  \n  key_flight_filter = Flights_filter.map(lambda x: (x[5],x[1]))\n  \n  #convert to \"Cessna XYZ\"\n  def seq(a,b):\n    if str(b)[26] == 'T':\n      return str(a) + ' ' + str(b)[27:30]\n    return str(a) + ' ' + str(b)[26:29]\n  \n  def combine(a,b):\n    return a\n  \n  key_manufact_filter = key_manufact_filter.aggregateByKey('Cessna', seq, combine)\n  \n  #join table \n  newRdd = key_manufact_filter.join(key_flight_filter)\n\n  #count number\n  count = newRdd.map(lambda x:(x[1][0], 1))\n  count = count.reduceByKey(lambda x,y: (x+y))\n  \n  #sort\n  count = count.map(lambda x:(x[1], x[0])).sortByKey(False)\n  result = count.map(lambda x:(x[1], x[0]))\n  \n  print(result.take(3))\n  \n  stagemetrics.end()\n  stagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fead7c2-6cd3-4716-9c77-dd6e79608d14"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["task_1_RDD1(spark, f\"{dbfs_fileStore_prefix}/{prefix}_flights_small.csv\", f\"{dbfs_fileStore_prefix}/{prefix}_aircrafts.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46b66f50-67b3-470d-a6da-df872c58a9bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;Cessna 172&#39;, 57), (&#39;Cessna 210&#39;, 48), (&#39;Cessna 421&#39;, 47)]\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 9\nnumTasks =&gt; 26\nelapsedTime =&gt; 6373 (6 s)\nstageDuration =&gt; 5565 (6 s)\nexecutorRunTime =&gt; 12023 (12 s)\nexecutorCpuTime =&gt; 758 (0.8 s)\nexecutorDeserializeTime =&gt; 792 (0.8 s)\nexecutorDeserializeCpuTime =&gt; 263 (0.3 s)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 0 (0 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 21 (21 ms)\nresultSize =&gt; 9510 (9.0 KB)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 21\nbytesRead =&gt; 6233456 (5.0 MB)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 181\nshuffleTotalBlocksFetched =&gt; 48\nshuffleLocalBlocksFetched =&gt; 48\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 872930 (852.0 KB)\nshuffleLocalBytesRead =&gt; 872930 (852.0 KB)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 871636 (851.0 KB)\nshuffleRecordsWritten =&gt; 165\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;Cessna 172&#39;, 57), (&#39;Cessna 210&#39;, 48), (&#39;Cessna 421&#39;, 47)]\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 9\nnumTasks =&gt; 26\nelapsedTime =&gt; 6373 (6 s)\nstageDuration =&gt; 5565 (6 s)\nexecutorRunTime =&gt; 12023 (12 s)\nexecutorCpuTime =&gt; 758 (0.8 s)\nexecutorDeserializeTime =&gt; 792 (0.8 s)\nexecutorDeserializeCpuTime =&gt; 263 (0.3 s)\nresultSerializationTime =&gt; 0 (0 ms)\njvmGCTime =&gt; 0 (0 ms)\nshuffleFetchWaitTime =&gt; 0 (0 ms)\nshuffleWriteTime =&gt; 21 (21 ms)\nresultSize =&gt; 9510 (9.0 KB)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 21\nbytesRead =&gt; 6233456 (5.0 MB)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 181\nshuffleTotalBlocksFetched =&gt; 48\nshuffleLocalBlocksFetched =&gt; 48\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 872930 (852.0 KB)\nshuffleLocalBytesRead =&gt; 872930 (852.0 KB)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 871636 (851.0 KB)\nshuffleRecordsWritten =&gt; 165\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["task_1_RDD1(spark, f\"{dbfs_fileStore_prefix}/{prefix}_flights_massive.csv\", f\"{dbfs_fileStore_prefix}/{prefix}_aircrafts.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85fb4045-2adf-4d96-9e24-8df78cbae7f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;Cessna 210&#39;, 37771), (&#39;Cessna 172&#39;, 32853), (&#39;Cessna 421&#39;, 32817)]\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 11\nnumTasks =&gt; 378\nelapsedTime =&gt; 1724894 (29 min)\nstageDuration =&gt; 1724261 (29 min)\nexecutorRunTime =&gt; 13527209 (3.8 h)\nexecutorCpuTime =&gt; 16785 (17 s)\nexecutorDeserializeTime =&gt; 8530 (9 s)\nexecutorDeserializeCpuTime =&gt; 1838 (2 s)\nresultSerializationTime =&gt; 7 (7 ms)\njvmGCTime =&gt; 2096358 (35 min)\nshuffleFetchWaitTime =&gt; 18 (18 ms)\nshuffleWriteTime =&gt; 14320 (14 s)\nresultSize =&gt; 154608 (150.0 KB)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 14191\nbytesRead =&gt; 2694212816 (2.0 GB)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 14589\nshuffleTotalBlocksFetched =&gt; 3445\nshuffleLocalBlocksFetched =&gt; 3445\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 485440241 (462.0 MB)\nshuffleLocalBytesRead =&gt; 485440241 (462.0 MB)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 485438424 (462.0 MB)\nshuffleRecordsWritten =&gt; 14566\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;Cessna 210&#39;, 37771), (&#39;Cessna 172&#39;, 32853), (&#39;Cessna 421&#39;, 32817)]\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages =&gt; 11\nnumTasks =&gt; 378\nelapsedTime =&gt; 1724894 (29 min)\nstageDuration =&gt; 1724261 (29 min)\nexecutorRunTime =&gt; 13527209 (3.8 h)\nexecutorCpuTime =&gt; 16785 (17 s)\nexecutorDeserializeTime =&gt; 8530 (9 s)\nexecutorDeserializeCpuTime =&gt; 1838 (2 s)\nresultSerializationTime =&gt; 7 (7 ms)\njvmGCTime =&gt; 2096358 (35 min)\nshuffleFetchWaitTime =&gt; 18 (18 ms)\nshuffleWriteTime =&gt; 14320 (14 s)\nresultSize =&gt; 154608 (150.0 KB)\ndiskBytesSpilled =&gt; 0 (0 Bytes)\nmemoryBytesSpilled =&gt; 0 (0 Bytes)\npeakExecutionMemory =&gt; 0\nrecordsRead =&gt; 14191\nbytesRead =&gt; 2694212816 (2.0 GB)\nrecordsWritten =&gt; 0\nbytesWritten =&gt; 0 (0 Bytes)\nshuffleRecordsRead =&gt; 14589\nshuffleTotalBlocksFetched =&gt; 3445\nshuffleLocalBlocksFetched =&gt; 3445\nshuffleRemoteBlocksFetched =&gt; 0\nshuffleTotalBytesRead =&gt; 485440241 (462.0 MB)\nshuffleLocalBytesRead =&gt; 485440241 (462.0 MB)\nshuffleRemoteBytesRead =&gt; 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk =&gt; 0 (0 Bytes)\nshuffleBytesWritten =&gt; 485438424 (462.0 MB)\nshuffleRecordsWritten =&gt; 14566\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Task 1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2331534238493179}},"nbformat":4,"nbformat_minor":0}
